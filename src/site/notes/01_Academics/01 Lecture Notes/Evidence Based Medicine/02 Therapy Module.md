---
{"dg-publish":true,"permalink":"/01-academics/01-lecture-notes/evidence-based-medicine/02-therapy-module/","tags":["IDC213,"]}
---

# Information
date:: 2022-09-26
lecturer:: Blas Mantaring

# üì¶ Resources
- 

# üìî Notes
## Appraising Directness
- Determine if the study provides a **direct enough answer** to the clinical question in terms of PEO elements
	- Compare the PEO of the clinical scenario vs PEO in the paper
- Directness provides **prescreening** of publications to determine its usefulness for application to the clinical scenario
	- ! If the PEO does not fit the clinical scenario, you might as well look for other papers
## Appraising Validity
### Were patients **randomly assigned** to the treatment group?
- Randomization is important for ==equalizing groups== as unequal groups may lead to false conclusion that the difference in outcome is due to the intervention of interest but due to inequalities between groups
- Randomization equalizes the *known and unknown* factors influencing the outcomes
	- Ensures that the patients have an **equal chance** of being allocated into treatment vs. control
- **Matching** is a methodology that attempts to equalize patients based on known criteria but this ==does not equalize unknown factors== (*not as good as randomization*)
- + If there is documentation of equality at the start of the study and inequality of outcomes at the end of the study, the inequality can be attributed to the intervention
- **Randomized trials** need ==adequate sample sizes== therefore, not all studies have to be randomized trials e.g., rare conditions with **case reports and case series** are still admissible evidence
### Was allocation concealed?
- **Allocation concealment** involves hiding the randomization lists from the test participants
	- Randomization can be disturbed by good intentions  
### Were baseline characteristics similar at the start of the trial?
- **p-values** are not recommended for use in large sample sizes as even the slightest difference might be deemed as statistically significant and small sample sizes make the largest difference be deemed as statistically insignificant
### Were patients blinded to treatment assignment?
- Patients join trials because they want to achieve the outcome of interest, and if patients are non-blinded, there is introduction of **co-interventions** that go on to influence the outcome 
### Were caregivers blinded to treatment assignment?
- Similar to introduction of co-interventions by patients who are non-blinded, caregivers can also introduce co-interventions that may be subtle enough to not be detected by the researchers
- **Performance bias** refers to bias from following up more frequently than the other study group resulting in the patients being more compliant due to the constant reminders
### Were outcome assessors blinded to the treatment assignment?
- Knowledge of treatment assignment can influence the reading or interpretation of results along with the rigor or manner of determining the outcome of patients referred to as **detection bias**
### Were all patients analyzed in the groups to which they were originally randomized?
- Analyzing patients in the groups were they were originally assigned to regardless if they received the treatment or not is called **intention-to-treat analysis**
	- Realistic to the compliance rates of patients **(real world analysis)**
	- Including all patients in the analysis helps address **exclusion bias**
	- Answers questions of **effectiveness**
- **Per-protocol or Censored analysis** involves analyzing patients based on the treatment they received and not the group they were originally assigned to
	- Also known as **ideal world** analysis as it assumes that all subjects perfectly complied with the assigned treatment
	- Answers questions of **efficacy**
### Was follow-up rate adequate?
- If patients are lost to follow-up, the results of the study changes because outcomes of those who did not follow-up are unknown
- If outcome rates are higher than the dropout rates, the dropouts will not change the conclusion of the study
- **Sensitivity analysis** involves assigning the worst case scenario for the treatment dropouts and the best case scenario for the control dropouts to see if the results of the study will change
- Addresses **attrition bias**
## Appraising Results
### Questions Asked
- How large was the treatment effect?
	- Use the reports of dichotomous outcomes e.g., RR, ARR
- How precise was the treatment effect?
	- Use the widths of the 95% confidence intervals
	- If CI is not given, use the **p-values** (probability of type I error)
## Assessing Applicability
- Are there biologic issues that may affect applicability of treatment?
	- Influences of **sex, comorbidities, race, age, and pathology (SCRAP)**
- Are there socioeconomic issues affecting applicability of treatment?
## Individualizing Results
- Compute for **patient-specific costs** of treatment
$$Cost\ to\ prevent\ 1\ additional\ outcome=NNT\times Cost_{treatment} \times Duration_{treatment}$$

# ‚ùì Questions
- 

# üéØ Tasks
- 

# üìì Summary





